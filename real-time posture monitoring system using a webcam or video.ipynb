{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install mediapipe if not already installed\n",
    "#!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd963a6",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/3j8BPdc.png\" style=\"height:500px\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a46dec",
   "metadata": {},
   "source": [
    "## üìå What it means:\n",
    "This measures the **angle between the left shoulder and left ear**.\n",
    "\n",
    "It indicates how much your **neck is tilted forward or backward**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Intuition:\n",
    "When sitting upright, your **ear should be vertically aligned above your shoulder**.\n",
    "\n",
    "If your ear is far forward (like when slouching or looking down), the **angle becomes sharper (smaller)**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Good posture:\n",
    "- `neck_angle` is **high** (e.g., **45¬∞‚Äì60¬∞ or more**)\n",
    "- Indicates your **neck is aligned properly**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùå Bad posture:\n",
    "- `neck_angle` is **low** (e.g., **< 25¬∞**)\n",
    "- Indicates you're likely **leaning your head forward**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb91b0",
   "metadata": {},
   "source": [
    "# webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5251134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "from mediapipe.python.solutions.pose import POSE_CONNECTIONS\n",
    "from datetime import datetime\n",
    "\n",
    "# ‚úÖ MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# ‚úÖ Helper functions\n",
    "def findDistance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "def findAngle(x1, y1, x2, y2):\n",
    "    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n",
    "    return int(180 / math.pi) * theta\n",
    "\n",
    "def sendWarning():\n",
    "    print(\"‚ö†Ô∏è Warning: You've been in bad posture too long!\")\n",
    "\n",
    "# ‚úÖ Parameters\n",
    "offset_threshold = 100\n",
    "neck_angle_threshold = 25\n",
    "torso_angle_threshold = 10\n",
    "time_threshold = 180  # seconds\n",
    "\n",
    "good_frames = 0\n",
    "bad_frames = 0\n",
    "\n",
    "# ‚úÖ Colors\n",
    "green = (127, 255, 0)\n",
    "red = (50, 50, 255)\n",
    "light_green = (127, 233, 100)\n",
    "yellow = (0, 255, 255)\n",
    "pink = (255, 0, 255)\n",
    "blue = (255, 0, 0)  # ‚úÖ Using blue instead of white\n",
    "\n",
    "# ‚úÖ Webcam setup\n",
    "cap = cv2.VideoCapture(0)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "frame_width, frame_height = 640, 360\n",
    "\n",
    "# ‚úÖ Output video file name\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_path = f\"webcam_posture_{timestamp}.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "print(\"üé• Press 'q' to stop recording...\")\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"‚ùå Webcam read failed.\")\n",
    "            break\n",
    "\n",
    "        image = cv2.resize(image, (frame_width, frame_height))\n",
    "        h, w = image.shape[:2]\n",
    "        image = cv2.flip(image, 1)\n",
    "\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        keypoints = pose.process(rgb_image)\n",
    "\n",
    "        if keypoints.pose_landmarks:\n",
    "            lm = keypoints.pose_landmarks.landmark\n",
    "            lmPose = mp_pose.PoseLandmark\n",
    "\n",
    "            # ‚úÖ Draw landmarks 0‚Äì24 with coordinates\n",
    "            for i in range(25):\n",
    "                cx = int(lm[i].x * w)\n",
    "                cy = int(lm[i].y * h)\n",
    "                cv2.circle(image, (cx, cy), 4, blue, -1)\n",
    "                cv2.putText(image, f'{i}', (cx + 5, cy - 5), font, 0.4, pink, 1)\n",
    "\n",
    "            # ‚úÖ Draw pose skeleton using MediaPipe-defined connections\n",
    "            for connection in mp_pose.POSE_CONNECTIONS:\n",
    "                start_idx = connection[0]\n",
    "                end_idx = connection[1]\n",
    "                x1, y1 = int(lm[start_idx].x * w), int(lm[start_idx].y * h)\n",
    "                x2, y2 = int(lm[end_idx].x * w), int(lm[end_idx].y * h)\n",
    "                cv2.line(image, (x1, y1), (x2, y2), blue, 2)\n",
    "\n",
    "            # ‚úÖ Posture analysis\n",
    "            l_shldr_x = int(lm[lmPose.LEFT_SHOULDER].x * w)\n",
    "            l_shldr_y = int(lm[lmPose.LEFT_SHOULDER].y * h)\n",
    "            r_shldr_x = int(lm[lmPose.RIGHT_SHOULDER].x * w)\n",
    "            r_shldr_y = int(lm[lmPose.RIGHT_SHOULDER].y * h)\n",
    "            l_ear_x = int(lm[lmPose.LEFT_EAR].x * w)\n",
    "            l_ear_y = int(lm[lmPose.LEFT_EAR].y * h)\n",
    "            l_hip_x = int(lm[lmPose.LEFT_HIP].x * w)\n",
    "            l_hip_y = int(lm[lmPose.LEFT_HIP].y * h)\n",
    "\n",
    "            offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n",
    "\n",
    "            if offset < offset_threshold:\n",
    "                cv2.putText(image, f'{int(offset)} Aligned', (w - 250, 30), font, 0.6, green, 2)\n",
    "            else:\n",
    "                cv2.putText(image, f'{int(offset)} Not aligned', (w - 250, 30), font, 0.6, red, 2)\n",
    "\n",
    "            neck_angle = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n",
    "            torso_angle = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)\n",
    "\n",
    "            if neck_angle < neck_angle_threshold and torso_angle < torso_angle_threshold:\n",
    "                bad_frames = 0\n",
    "                good_frames += 1\n",
    "                posture = \"Good Posture\"\n",
    "                color = light_green\n",
    "            else:\n",
    "                good_frames = 0\n",
    "                bad_frames += 1\n",
    "                posture = \"Bad Posture\"\n",
    "                color = red\n",
    "\n",
    "            cv2.putText(image, f'Neck: {int(neck_angle)}¬∞', (10, 30), font, 0.6, color, 2)\n",
    "            cv2.putText(image, f'Torso: {int(torso_angle)}¬∞', (10, 60), font, 0.6, color, 2)\n",
    "            cv2.putText(image, posture, (10, h - 20), font, 0.8, color, 2)\n",
    "\n",
    "            # Custom posture lines\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), color, 2)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), color, 2)\n",
    "\n",
    "            if bad_frames / fps > time_threshold:\n",
    "                sendWarning()\n",
    "\n",
    "        # ‚úÖ Save & Show\n",
    "        video_writer.write(image)\n",
    "        cv2.imshow(\"Webcam Posture Tracking\", image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"üõë Exited by user.\")\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"üõë Stopped by keyboard interrupt\")\n",
    "\n",
    "# ‚úÖ Cleanup\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"‚úÖ Video saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5288db8a",
   "metadata": {},
   "source": [
    "# video data(testvideo.mp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75932621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import mediapipe as mp\n",
    "from mediapipe.python.solutions.pose import POSE_CONNECTIONS\n",
    "\n",
    "# ‚úÖ MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# ‚úÖ Helper functions\n",
    "def findDistance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "def findAngle(x1, y1, x2, y2):\n",
    "    theta = math.acos((y2 - y1) * (-y1) / (math.sqrt((x2 - x1)**2 + (y2 - y1)**2) * y1))\n",
    "    return int(180 / math.pi) * theta\n",
    "\n",
    "def sendWarning():\n",
    "    print(\"‚ö†Ô∏è Warning: You've been in bad posture too long!\")\n",
    "\n",
    "# ‚úÖ Parameters\n",
    "offset_threshold = 100\n",
    "neck_angle_threshold = 25\n",
    "torso_angle_threshold = 10\n",
    "time_threshold = 180  # seconds\n",
    "\n",
    "good_frames = 0\n",
    "bad_frames = 0\n",
    "\n",
    "# ‚úÖ Colors\n",
    "green = (127, 255, 0)\n",
    "red = (50, 50, 255)\n",
    "light_green = (127, 233, 100)\n",
    "yellow = (0, 255, 255)\n",
    "pink = (255, 0, 255)\n",
    "white = (255, 255, 255)\n",
    "\n",
    "# ‚úÖ Load video\n",
    "input_path = \"test.mp4\"  # Your video file\n",
    "cap = cv2.VideoCapture(input_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "frame_width, frame_height = 640, 360\n",
    "\n",
    "# ‚úÖ Setup VideoWriter\n",
    "output_path = \"output_posture.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"‚úÖ Video complete.\")\n",
    "            break\n",
    "\n",
    "        image = cv2.resize(image, (frame_width, frame_height))\n",
    "        h, w = image.shape[:2]\n",
    "        image = cv2.flip(image, 1)\n",
    "\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        keypoints = pose.process(rgb_image)\n",
    "\n",
    "        if keypoints.pose_landmarks:\n",
    "            lm = keypoints.pose_landmarks.landmark\n",
    "            lmPose = mp_pose.PoseLandmark\n",
    "\n",
    "            # ‚úÖ Draw all landmark points (0‚Äì24)\n",
    "            for i in range(0, 25):\n",
    "                cx = int(lm[i].x * w)\n",
    "                cy = int(lm[i].y * h)\n",
    "                cv2.circle(image, (cx, cy), 4, white, -1)\n",
    "                cv2.putText(image, f'{i}', (cx + 5, cy - 5), font, 0.4, pink, 1)\n",
    "\n",
    "            # ‚úÖ Connect landmarks using MediaPipe official connections\n",
    "            for connection in mp_pose.POSE_CONNECTIONS:\n",
    "                start_idx, end_idx = connection\n",
    "                x1, y1 = int(lm[start_idx].x * w), int(lm[start_idx].y * h)\n",
    "                x2, y2 = int(lm[end_idx].x * w), int(lm[end_idx].y * h)\n",
    "                cv2.line(image, (x1, y1), (x2, y2), white, 2)\n",
    "\n",
    "            # ‚úÖ Posture analysis landmarks\n",
    "            l_shldr_x = int(lm[lmPose.LEFT_SHOULDER].x * w)\n",
    "            l_shldr_y = int(lm[lmPose.LEFT_SHOULDER].y * h)\n",
    "            r_shldr_x = int(lm[lmPose.RIGHT_SHOULDER].x * w)\n",
    "            r_shldr_y = int(lm[lmPose.RIGHT_SHOULDER].y * h)\n",
    "            l_ear_x = int(lm[lmPose.LEFT_EAR].x * w)\n",
    "            l_ear_y = int(lm[lmPose.LEFT_EAR].y * h)\n",
    "            l_hip_x = int(lm[lmPose.LEFT_HIP].x * w)\n",
    "            l_hip_y = int(lm[lmPose.LEFT_HIP].y * h)\n",
    "\n",
    "            offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n",
    "            if offset < offset_threshold:\n",
    "                cv2.putText(image, f'{int(offset)} Aligned', (w - 250, 30), font, 0.6, green, 2)\n",
    "            else:\n",
    "                cv2.putText(image, f'{int(offset)} Not aligned', (w - 250, 30), font, 0.6, red, 2)\n",
    "\n",
    "            neck_angle = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n",
    "            torso_angle = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)\n",
    "\n",
    "            if neck_angle < neck_angle_threshold and torso_angle < torso_angle_threshold:\n",
    "                bad_frames = 0\n",
    "                good_frames += 1\n",
    "                posture = \"Good Posture\"\n",
    "                color = light_green\n",
    "            else:\n",
    "                good_frames = 0\n",
    "                bad_frames += 1\n",
    "                posture = \"Bad Posture\"\n",
    "                color = red\n",
    "\n",
    "            # ‚úÖ Text + custom pose lines\n",
    "            cv2.putText(image, f'Neck: {int(neck_angle)}¬∞', (10, 30), font, 0.6, color, 2)\n",
    "            cv2.putText(image, f'Torso: {int(torso_angle)}¬∞', (10, 60), font, 0.6, color, 2)\n",
    "            cv2.putText(image, posture, (10, h - 20), font, 0.8, color, 2)\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), color, 2)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), color, 2)\n",
    "\n",
    "            if bad_frames / fps > time_threshold:\n",
    "                sendWarning()\n",
    "\n",
    "        # ‚úÖ Save and show\n",
    "        video_writer.write(image)\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(rgb_image)\n",
    "        clear_output(wait=True)\n",
    "        display(pil_img)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"üõë Stopped manually\")\n",
    "            break\n",
    "\n",
    "        time.sleep(1 / fps)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"üõë Interrupted\")\n",
    "\n",
    "# ‚úÖ Cleanup\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"‚úÖ Output video saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f229bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
